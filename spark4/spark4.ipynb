{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75580664-f645-43ae-998d-070a02b7f012",
   "metadata": {},
   "source": [
    "### RDD缓存  保留血缘关系\n",
    "\n",
    "分散存储在服务器内部"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4477ff44-16cf-46d0-bb5c-ba56c908b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.cache() #内存缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82975949-76cb-44ce-82e3-c360773ffd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.persist(StorageLevel.MEMORY_ONLY)  #只内存缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e24d3c-9c1b-4cda-9bc9-58984a97e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.persist(StorageLevel.DISK_ONLY)  #只硬盘缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c51e84-71d2-4638-b9df-5f950bd73f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.persist(StorageLevel.MEMORY_AND_DISK)  #内存不够,硬盘缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bba575-4236-4ecf-8063-fbc2210540c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.persist(StorageLevel.OFF_HEAP)  #内存不够,硬盘缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba78950-a7ad-4061-92ab-f96b0ffb0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.unpersist() #主动清理缓存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4699f720-c72f-4a25-903c-e61631a7d7ca",
   "metadata": {},
   "source": [
    "## 演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b6362a-7852-4b8e-b87d-cd24f2577d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf,SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97a51e47-0e52-4f07-9350-ba211545dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.storagelevel import StorageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e17565a-ba68-4184-9634-bff01213143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=SparkConf().setAppName('spark4').setMaster('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2bfd81d-a575-4abf-9e73-75a61d62fb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/11 13:18:56 WARN Utils: Your hostname, MaQiang resolves to a loopback address: 127.0.1.1; using 192.168.1.110 instead (on interface wlp2s0)\n",
      "22/05/11 13:18:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "22/05/11 13:18:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sc=SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6adfb01a-82b6-45f2-b689-498ad9bff524",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd=sc.textFile('txt/spark3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28e5cf0a-cf04-4ed6-96d2-e27ad0b6b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1=rdd.flatMap(lambda x:x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70d81ad6-625f-45ee-99d2-9e468b487593",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2=rdd1.map(lambda x:(x,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "766d0bfa-196b-4157-915e-8b03825ee703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "# rdd2.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ef8a49f-7550-42b3-a353-48c2ed4a50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd3=rdd2.reduceByKey(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20fc85d8-5a0d-4d3d-a3a8-8ab15cd338de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('test', 3),\n",
       " ('qiang', 2),\n",
       " ('hadoop', 1),\n",
       " ('hello', 3),\n",
       " ('txt', 2),\n",
       " ('spark', 2)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e0ccaaf-5819-4312-9def-c7a3ed49d55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd4=rdd2.groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "638a1a98-bb56-4745-85f5-e0af977b251f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('test', <pyspark.resultiterable.ResultIterable at 0x7f02c0a99280>),\n",
       " ('qiang', <pyspark.resultiterable.ResultIterable at 0x7f02c0a99550>),\n",
       " ('hadoop', <pyspark.resultiterable.ResultIterable at 0x7f02c0a995b0>),\n",
       " ('hello', <pyspark.resultiterable.ResultIterable at 0x7f02c0a99610>),\n",
       " ('txt', <pyspark.resultiterable.ResultIterable at 0x7f02c0a99670>),\n",
       " ('spark', <pyspark.resultiterable.ResultIterable at 0x7f02c0a996d0>)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00d9166a-6845-4cb2-b009-f50184b30f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe62ebd3-3c9b-4737-8556-b5ee9c26297b",
   "metadata": {},
   "source": [
    "## 不保留血缘关系备份 : CheckPoint\n",
    "\n",
    "集中储存在hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23bc9113-9924-428a-b1f1-75c90c3d72e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1=rdd.flatMap(lambda x:x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d78c3949-2816-448b-a1d4-f0e3133b74ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2=rdd1.map(lambda x:(x,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab359f2a-5a13-4928-acc1-ea3093bc3738",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setCheckpointDir('checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1799edeb-86a4-41d7-be62-0b997b679bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2.checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fabe236-a27e-461c-b7c4-f3efa362acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd3=rdd2.reduceByKey(lambda x,y:x+y) #直接从checkpoint 开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3546660e-8242-495a-b850-1be6b1751f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('test', 3),\n",
       " ('qiang', 2),\n",
       " ('hadoop', 1),\n",
       " ('hello', 3),\n",
       " ('txt', 2),\n",
       " ('spark', 2)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc4cdc5-6d9f-4fd6-a4d1-838d8b50f2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
