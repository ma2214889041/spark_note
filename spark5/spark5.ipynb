{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "619625d8-7f32-4c79-a873-728f7a93665d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/12 12:37:39 WARN Utils: Your hostname, MaQiang resolves to a loopback address: 127.0.1.1; using 192.168.1.110 instead (on interface wlp2s0)\n",
      "22/05/12 12:37:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "22/05/12 12:37:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf,SparkContext\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "conf=SparkConf().setAppName('spark5').setMaster('local[*]')\n",
    "sc=SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e126798e-e5d1-4c9e-ba4b-89e4dfdefe26",
   "metadata": {},
   "source": [
    "## 广播变量 : 提前将本地list  --> RDD\n",
    "\n",
    "广播变量,提交给执行者,节约内存和通讯时间\n",
    "\n",
    "### (当本地list不大时候 广播效率比 RDD->RDD快)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47399f91-9ef7-4dd2-a0fa-fd6041c28dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[(1,'qiang',11),(2,'ma',13),(3,\"tiantian\",15),(4,'hushuop',67)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93a426a1-ac90-4740-bd7a-1a315be702ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list=sc.broadcast(l)   #提前声明为广播变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84ecf331-99ac-422a-837a-29292ce0aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd=sc.parallelize([(1,'math',99),(2,'fisica',40),(3,'english',67),(4,'python',788),(3,'read',467)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da4b8abf-9359-458c-9a1d-c8d91b468a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(x):\n",
    "    name=''\n",
    "    for i in name_list.value:  #name.vaule 可以当作使用list\n",
    "        if x[0]==i[0]:\n",
    "            name=i[1]\n",
    "    return (name,x[1],x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e14042bc-fdda-49de-9f30-b37c56edfb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('qiang', 'math', 99),\n",
       " ('ma', 'fisica', 40),\n",
       " ('tiantian', 'english', 67),\n",
       " ('hushuop', 'python', 788),\n",
       " ('tiantian', 'read', 467)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.map(fun).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b571c-e2e6-48ff-8279-547da5d066b3",
   "metadata": {},
   "source": [
    "## 累加器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "266c1303-76da-4e4f-a601-909c154b5641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "rdd= sc.parallelize([1,2,3,4,5,6,7,8,9,10],2)\n",
    "count= 0 \n",
    "def fun(x):\n",
    "    global count\n",
    "    count+=1\n",
    "    print(count)\n",
    "    \n",
    "rdd.map(fun).collect()\n",
    "print(count)   #输出是0,因为 count传给执行者,在分区内累加,不会传给driver ,应该是10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "230f41d7-8510-4d3b-a1dc-72d6377a1315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# 提前声明为累加器变量,结果是10\n",
    "rdd= sc.parallelize([1,2,3,4,5,6,7,8,9,10],2)\n",
    "count= sc.accumulator(0)\n",
    "def fun(x):\n",
    "    global count\n",
    "    count+=1\n",
    "    print(count)\n",
    "    \n",
    "rdd.map(fun).collect()\n",
    "print(count)   #输出是10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf5218b-280f-47e1-8558-1a2f84402115",
   "metadata": {},
   "source": [
    "# DAG图  sparkUI查看"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038c50d6-b8b9-4ea8-8f26-8931efa97419",
   "metadata": {},
   "source": [
    "宽依赖 : 父亲有多个子  (shuffuer)\n",
    "窄依赖 : 其他情况\n",
    "\n",
    "一个stage内部都是 ''' 窄依赖 '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53da77ca-2001-4763-9b63-122978386cd9",
   "metadata": {},
   "source": [
    "## spark 并行度\n",
    "\n",
    "cpu核心的2-10倍数,一般不要改全局并行度(分区数)\n",
    "### 不让CPU空闲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fffecca-9841-4b27-81de-6962700dc3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
